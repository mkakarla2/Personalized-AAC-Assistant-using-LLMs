# Personalized AAC Assistant Using Large Language Models (LLMs)

**Authors**: Mohan Kakarla, Udit Brahmadevara  


---

## ğŸ§  Abstract

Augmentative and Alternative Communication (AAC) systems assist individuals with speech impairments. However, most existing AAC tools generate generic and impersonal text that fails to reflect usersâ€™ identities, experiences, or communicative intent. This project leverages Large Language Models (LLMs), personalization, and Retrieval-Augmented Generation (RAG) to enable more expressive and contextually grounded AAC outputs.

We aim to build a system that understands the userâ€™s history, preferences, and prior conversations and then generates tailored responses to improve inclusiveness, emotional accuracy, and overall communicative authenticity.

---

## ğŸ¯ Objectives

- Develop a personalized AAC assistant using a finetuned LLM.
- Incorporate Retrieval-Augmented Generation (RAG) for memory retrieval.
- Enable persona-aware prompting to match a user's style, tone, and prior context.
- Provide a user-friendly interface for AAC users to interact via the model.

---

## ğŸ—ï¸ System Architecture

- **Frontend**: Streamlit interface  
- **Backend**:  
  - Finetuned LLaMA model (loaded via HuggingFace or local path)  
  - FAISS-based vector store to store and retrieve user-specific memory  
  - Personalization layer (prompt engineering with profiles)  
- **Data Format**: JSON file for user histories (`user_profiles.json`)  
- **Archutecture**:  
  ![System Architecture](media/architecture.png)
- **Fronted UI**:  
  ![UI Screenshot](media/ui.png)

---

## ğŸ§ª Key Features

- ğŸ¤– Finetuned LLM to generate expressive responses  
- ğŸ§  Memory-aware RAG embeds user profile and history into every response  
- ğŸ‘¤ Multiple personas and modes (friendly, emotional, fact-based)  
- ğŸ¥ Demo available: [Demo.mp4](Demo.mp4)

---

## ğŸ“ File Structure

```
â”œâ”€â”€ app.py              # Streamlit frontend
â”œâ”€â”€ Code.ipynb          # Main logic development
â”œâ”€â”€ Training.ipynb      # Fine-tuning and model experimentation
â”œâ”€â”€ user_profiles.json  # Stores prior conversations and preferences
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ report.pdf          # Academic paper
â”œâ”€â”€ Demo.mp4            # Demo video
â””â”€â”€ media/
    â”œâ”€â”€ architecture.png
    â””â”€â”€ ui.png
```

---

## ğŸ“¦ Model Weights

Due to GitHub size limits, model weights are hosted on Kaggle:

ğŸ“¥ **Download Finetuned LLM (~5â€¯GB)**  
https://www.kaggle.com/datasets/mohankumarkakarla/finetuned/data

After downloading, place the model files in:

```
./models/llm_finetuned/
```

---

## ğŸš€ Running the App

### 1. Install dependencies
```bash
pip install -r requirements.txt
```

### 2. Launch Streamlit
```bash
streamlit run app.py
```

---

## ğŸ› ï¸ Technologies Used

- **Model**: LLaMAâ€‘3â€‘8Bâ€‘Instruct (4â€‘bit)  
- **Vector Store**: FAISS  
- **Embeddings**: Sentenceâ€‘BERT  
- **Frameworks**: PyTorch, Hugging Face Transformers, LangChain, Streamlit

---



---

## ğŸ“ƒ License

Released for **academic and research purposes only**. See `/LICENSE` for details.
